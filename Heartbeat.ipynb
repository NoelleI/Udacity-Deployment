{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heartbeat.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPKRMTu6yqKngXV1cBgN/UQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoelleI/Udacity-Deployment/blob/master/Heartbeat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5H_sr2Fu22c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7757ae30-3d96-4735-c524-3d58d4852c29"
      },
      "source": [
        "pip install mtcnn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mtcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (2.3.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lhsOd7yuFWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "'''Step 1 Detect Skin \n",
        "this code was adapted from https://www.pyimagesearch.com/2014/08/18/skin-detection-step-step-example-using-python-opencv/\n",
        "and\n",
        "https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/'''\n",
        "\n",
        "# import the necessary packages\n",
        "import imutils\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "from matplotlib import pyplot\n",
        "from mtcnn import MTCNN\n",
        "from google.colab.patches import cv2_imshow\n",
        "# construct the argument parse and parse the arguments\n",
        "\n",
        "# define the upper and lower boundaries of the HSV pixel\n",
        "# intensities to be considered 'skin'\n",
        "lower = np.array([0, 48, 80], dtype = \"uint8\")\n",
        "upper = np.array([20, 255, 255], dtype = \"uint8\")\n",
        "# if a video path was not supplied, grab the reference\n",
        "# to the gray\n",
        "\n",
        "\n",
        "camera = cv2.VideoCapture(\"skin_detect.MOV\")\n",
        "n_frames = int(camera.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "#classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "\n",
        "''''change this'''\n",
        "\n",
        "# keep looping over the frames in the video\n",
        "for i in range(n_frames):\n",
        "    \n",
        "    print(i)\n",
        "\t# grab the current frame\n",
        "    (grabbed, frame) = camera.read()\n",
        "\t# if we are viewing a video and we did not grab a\n",
        "\t# frame, then we have reached the end of the video\n",
        "\t# resize the frame, convert it to the HSV color space,\n",
        "\t# and determine the HSV pixel intensities that fall into\n",
        "\t# the speicifed upper and lower boundaries\n",
        "    if grabbed:\n",
        "        frame = imutils.resize(frame, width = 400)\n",
        "    \n",
        "        converted = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        skinMask = cv2.inRange(converted, lower, upper)\n",
        "\t# apply a series of erosions and dilations to the mask\n",
        "\t# using an elliptical kernel\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
        "        skinMask = cv2.erode(skinMask, kernel, iterations = 2)\n",
        "        skinMask = cv2.dilate(skinMask, kernel, iterations = 2)\n",
        "\t# blur the mask to help remove noise, then apply the\n",
        "\t# mask\n",
        "        skinMask = cv2.GaussianBlur(skinMask, (3, 3), 0)\n",
        "        skin = cv2.bitwise_and(frame, frame, mask = skinMask)\n",
        "\t# show the skin in the image along with the mask\n",
        "        #cv2_imshow(np.vstack([frame, skin]))\n",
        "        detector = MTCNN()\n",
        "        # detect faces in the image\n",
        "        faces = detector.detect_faces(frame)\n",
        "        print(\"len faces =\", len(faces))\n",
        "        \n",
        "    \n",
        "        #bboxes = classifier.detectMultiScale(frame, 1.0005, 3)\n",
        "# print bounding box for each detected face\n",
        "        #for box in bboxes:\n",
        "            #print(box)\n",
        "\t# if the 'q' key is pressed, stop the loop\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "# cleanup the camera and close any open windows\n",
        "camera.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMz7jDdau87G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}